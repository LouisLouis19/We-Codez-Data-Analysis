<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction to Pandas</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header>
      <h1>Introduction to Pandas</h1>
    </header>

    <div class="container">
      <aside class="sidebar">
        <nav>
          <ul>
            <li>
              <a href="index.html" class="active">Introduction to Pandas</a>
            </li>
          </ul>
        </nav>
      </aside>
      <main>
        <section class="overview">
          <h2>Introduction to Pandas</h2>
          <p>
            Pandas is a powerful library for data analysis and manipulation in
            Python. It provides data structures like Series and DataFrame, which
            are essential for handling and analyzing data.
          </p>

          <h3>What is Pandas?</h3>
          <p>
            Pandas is a data analysis and manipulation library. It is widely
            used for cleaning, analyzing, and visualizing data. It provides two
            primary data structures: Series and DataFrame, which allow for
            efficient data handling.
          </p>

          <h3>Installation</h3>
          <p>To install Pandas, use pip:</p>
          <pre class="code-block">pip install pandas</pre>
          <p>To check the version of Pandas installed:</p>
          <pre class="code-block">
import pandas as pd
print(pd.__version__)</pre
          >
        </section>

        <section class="getting-started">
          <h2>Getting Started</h2>

          <h3>Importing Pandas</h3>
          <p>To use Pandas, you need to import it into your Python script:</p>
          <pre class="code-block">import pandas as pd</pre>

          <h3>Pandas Data Structures</h3>
          <p>Pandas provides two primary data structures:</p>
          <ul>
            <li>
              <strong>Series</strong>: A one-dimensional array-like object.
            </li>
            <li>
              <strong>DataFrame</strong>: A two-dimensional, size-mutable, and
              potentially heterogeneous tabular data structure.
            </li>
          </ul>
        </section>

        <section class="creating-structures">
          <h2>Creating DataFrames and Series</h2>

          <h3>Creating a Series</h3>
          <p>
            Series can be created from lists, dictionaries, or scalar values:
          </p>
          <pre class="code-block">
import pandas as pd

# From a list
series_list = pd.Series([1, 2, 3, 4])

# With custom index
series_custom = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])</pre
          >

          <h3>Creating a DataFrame</h3>
          <p>
            DataFrames can be created from dictionaries, lists of lists, or by
            reading from files:
          </p>
          <pre class="code-block">
import pandas as pd

# From a dictionary
data_dict = {'Column1': [1, 2], 'Column2': [3, 4]}
df_dict = pd.DataFrame(data_dict)
df_dict_index = pd.DataFrame(data_dict, index = ["row1", "row2"])

# From a list of lists
data_list = [[1, 2], [3, 4]]
df_list = pd.DataFrame(data_list, index=['row1', 'row2'], columns=['Column1', 'Column2'])</pre
          >
        </section>

        <section class="exploring-dataframes">
          <h2>Exploring DataFrames</h2>

          <h3>Basic DataFrame Operations</h3>
          <p>Perform basic operations to view and understand your data:</p>
          <pre class="code-block">
import pandas as pd

df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
print(df.head())  # View the first 5 rows
print(df.tail())  # View the last 5 rows
print(df.info())  # Get basic info about the DataFrame</pre
          >

          <h3>Descriptive Statistics</h3>
          <p>Use descriptive statistics to summarize the data:</p>
          <pre class="code-block">
import pandas as pd

df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})
print(df.describe())  # Summary statistics for numerical columns</pre
          >
        </section>

        <section class="indexing-selecting">
          <h2>Indexing and Selecting Data</h2>

          <h3>Selecting Columns and Rows</h3>
          <p>
            Select columns and rows using column names, `.loc[]`, and `.iloc[]`:
          </p>
          <pre class="code-block">
import pandas as pd

df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})
print(df['A'])            # Select a column
print(df.loc[0])         # Select a row by label
print(df.iloc[0])        # Select a row by position</pre
          >

          <h3>Boolean Indexing</h3>
          <p>Filter rows based on conditions:</p>
          <pre class="code-block">
import pandas as pd

df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
filtered_df = df[df['A'] > 1]
print(filtered_df)</pre
          >
        </section>

        <section class="data-cleaning">
          <h2>Data Cleaning</h2>
          <p>
            Data cleaning means fixing bad data in your data set. Bad data can
            include:
          </p>
          <ul>
            <li>
              <strong>Empty Cells:</strong> Missing values that need to be
              handled.
            </li>
            <li>
              <strong>Data in Wrong Format:</strong> Values that are not in the
              expected format (e.g., dates stored as strings).
            </li>
            <li>
              <strong>Wrong Data:</strong> Incorrect or inconsistent values that
              need correction.
            </li>
            <li>
              <strong>Duplicates:</strong> Duplicate rows or entries that should
              be removed.
            </li>
          </ul>

          <h3>Handling Missing Values</h3>
<p>
  To handle missing values, you can either fill them with a specified value or drop the rows with missing values. You can also fill missing values with the mean, median, or mode of the column:
</p>
<pre class="code-block">
import pandas as pd
import numpy as np

# Create a DataFrame with missing values
data = {'A': [1, np.nan, 3], 'B': [4, 5, np.nan], 'C': [np.nan, 2, 3]}
df = pd.DataFrame(data)

# Fill missing values with a specific value
df_filled_value = df.fillna(0)  # Fill missing values with 0

# Drop rows with missing values
df_dropped = df.dropna()  # Drop rows with missing values

# Fill missing values with the mean of the column
mean_values = df.mean()
df_filled_mean = df.fillna(mean_values)

# Fill missing values with the median of the column
median_values = df.median()
df_filled_median = df.fillna(median_values)

# Fill missing values with the mode of the column
mode_values = df.mode().iloc[0]
df_filled_mode = df.fillna(mode_values)

print("Filled with 0:")
print(df_filled_value)
print("\nDropped rows with missing values:")
print(df_dropped)
print("\nFilled with mean values:")
print(df_filled_mean)
print("\nFilled with median values:")
print(df_filled_median)
print("\nFilled with mode values:")
print(df_filled_mode)
</pre>


<h3>Correcting Data Types</h3>
<p>Data of wrong format can make it difficult, or even impossible, to analyze data. To convert columns to the correct data type, and handle any resulting issues:</p>
<pre class="code-block">
import pandas as pd
import numpy as np

# Create a DataFrame with incorrect data types
data = {'Date': ['2024-01-01', '2024-01-02', 'invalid-date'],
        'Value': ['100', '200', 'not-a-number']}
df = pd.DataFrame(data)

# Convert 'Date' column to datetime
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')  # 'invalid-date' becomes NaT

# Convert 'Value' column to numeric
df['Value'] = pd.to_numeric(df['Value'], errors='coerce')  # 'not-a-number' becomes NaN

# Remove rows with NaT or NaN values
df_cleaned = df.dropna()

print("Original DataFrame:")
print(df)
print("\nCleaned DataFrame (after converting and removing rows with NaT or NaN):")
print(df_cleaned)
</pre>

<h3>Fixing Wrong Data</h3>
<p>Data can sometimes contain incorrect or inconsistent values that need to be corrected. You can fix wrong data using boolean indexing to identify and correct these issues:</p>
<pre class="code-block">
import pandas as pd
import numpy as np

# Create a DataFrame with some wrong data
data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],
        'Age': [24, -1, 30, 150],  # -1 and 150 are incorrect ages
        'Salary': [50000, 60000, -7000, 80000]}  # -7000 is an incorrect salary
df = pd.DataFrame(data)

# Identify and fix incorrect data
# For 'Age': Assuming valid ages should be between 0 and 120
df.loc[df['Age'] < 0, 'Age'] = np.nan  # Replace negative ages with NaN
df.loc[df['Age'] > 120, 'Age'] = np.nan  # Replace ages greater than 120 with NaN

# For 'Salary': Assuming valid salaries should be non-negative
df.loc[df['Salary'] < 0, 'Salary'] = np.nan  # Replace negative salaries with NaN

# Fill NaN values with a specified value (e.g., median or mean)
df['Age'] = df['Age'].fillna(df['Age'].median())
df['Salary'] = df['Salary'].fillna(df['Salary'].median())

print("Original DataFrame:")
print(df)
print("\nDataFrame after fixing wrong data:")
print(df)
</pre>



<h3>Removing Duplicates</h3>
<p>Removing duplicate rows from a DataFrame helps ensure the data is unique and accurate. You can first check for duplicated rows using the `.duplicated()` method, and then remove them using the `.drop_duplicates()` method:</p>

<pre class="code-block">
import pandas as pd

# Create a DataFrame with some duplicate rows
data = {'A': [1, 2, 2, 1], 'B': [3, 4, 4, 3]}
df = pd.DataFrame(data)

# Check for duplicated rows
duplicates = df.duplicated()
print("Duplicated rows:\n", duplicates)

# Remove duplicate rows
df_unique = df.drop_duplicates()
print("\nDataFrame after removing duplicates:\n", df_unique)

# Remove duplicates based on specific columns
df_unique_cols = df.drop_duplicates(subset=['A'])
print("\nDataFrame after removing duplicates based on column 'A':\n", df_unique_cols)
</pre>

<p>
  The `.duplicated()` method returns a Boolean Series indicating whether each row is a duplicate of a previous row. You can use this method to identify and review duplicates before deciding to remove them.
</p>
<p>
  The `.drop_duplicates()` method removes duplicate rows, and you can specify columns with the `subset` parameter to remove duplicates based on specific columns only.
</p>

        </section>

        <section class="practice-exercises">
          <h2>Practice Exercises</h2>
        
          <h3>Simple Exercises</h3>
          <h4>1. Create a DataFrame from a Dictionary</h4>
          <p>
            Create a DataFrame from a dictionary where the keys are column names and the values are lists of data.
          </p>
          <details>
            <summary>Solution</summary>
            <div>
              <pre class="code-block">import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [24, 27, 22]}
df = pd.DataFrame(data)
print(df)</pre>
            </div>
          </details>
          <br>
        
          <h4>2. Handle Missing Data</h4>
          <p>
            Create a DataFrame with some missing values. Fill missing values with a specified value or drop rows with missing values.
          </p>
          <details>
            <summary>Solution</summary>
            <div>
              <pre class="code-block">import pandas as pd
import numpy as np

data = {'A': [1, np.nan, 3], 'B': [4, 5, np.nan]}
df = pd.DataFrame(data)
df_filled = df.fillna(0)  # Fill missing values with 0
df_dropped = df.dropna()  # Drop rows with missing values
print(df_filled)
print(df_dropped)</pre>
            </div>
          </details>
          <br>

            <h4>3. Indexing and Selecting Data</h4>
            <p>
            Create a DataFrame with the following code:
            <br><br>
            <pre class="code-block">import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],
        'Age': [28, 22, 35, 30],
        'City': ['New York', 'Los Angeles', 'Chicago', 'New York']}
df = pd.DataFrame(data)
            </pre>
            Perform the following tasks:
            <ol>
                <li>Select the "City" column.</li>
                <li>Select the row where the "Name" is "Charlie".</li>
                <li>Select the row where the index is 1.</li>
            </ol>
            </p>
            <details>
            <summary>Solution</summary>
            <div>
                <pre class="code-block">import pandas as pd

data = {'Name': ['Alice', 'Bob', 'Charlie', 'David'],
        'Age': [28, 22, 35, 30],
        'City': ['New York', 'Los Angeles', 'Chicago', 'New York']}
df = pd.DataFrame(data)

# 1. Select the "City" column
city_column = df['City']

# 2. Select the row where the "Name" is "Charlie"
charlie_row = df[df['Name'] == 'Charlie']

# 3. Select the row where the index is 1
row_index_1 = df.iloc[1]

print(city_column)
print(charlie_row)
print(row_index_1)
                </pre>
            </div>
            </details>
            <br>

            <h4>4. Boolean Indexing</h4>
            <p>
              Using the following code to create a DataFrame:
              <br><br>
              <pre class="code-block">import pandas as pd

data = {'Product': ['A', 'B', 'C', 'D'],
        'Price': [10, 15, 20, 5],
        'Quantity': [5, 0, 3, 8]}
df = pd.DataFrame(data)
              </pre>
              <ol>
                <li>Filter the DataFrame to include only the rows where the "Price" is greater than 10 and the "Quantity" is greater than 2.</li>
                <li>Filter the DataFrame to include only the rows where the "Price" is even and the "Quantity" is odd.</li>
                <li>Filter the DataFrame to include only the rows where the "Price" is greater than the "Quantity."</li>
              </ol>
            </p>
            <details>
              <summary>Solution</summary>
              <div>
                <pre class="code-block">import pandas as pd

data = {'Product': ['A', 'B', 'C', 'D'],
        'Price': [10, 15, 20, 5],
        'Quantity': [5, 0, 3, 8]}
df = pd.DataFrame(data)

# 1. Filter the DataFrame to include only the rows where the "Price" is greater than 10 and the "Quantity" is greater than 2
filtered_df_1 = df[(df['Price'] > 10) & (df['Quantity'] > 2)]
print('Filter 1:\n', filtered_df_1)

# 2. Filter the DataFrame to include only the rows where the "Price" is even and the "Quantity" is odd
filtered_df_2 = df[(df['Price'] % 2 == 0) & (df['Quantity'] % 2 != 0)]
print('Filter 2:\n', filtered_df_2)

# 3. Filter the DataFrame to include only the rows where the "Price" is greater than the "Quantity"
filtered_df_3 = df[df['Price'] > df['Quantity']]
print('Filter 3:\n', filtered_df_3)
                </pre>
              </div>
            </details>
            
<br>

<h4>5. Data Cleaning</h4>
<p>
  Create a DataFrame with some missing values using the following code:
  <br><br>
  <pre class="code-block">
import pandas as pd
import numpy as np

data = {'ID': [1, 2, 3, 4, 5],
        'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
        'Age': [25, np.nan, 30, 28, np.nan],
        'Salary': [50000, 55000, np.nan, 60000, np.nan]}
df = pd.DataFrame(data)
  </pre>
  Perform the following tasks:
  <ol>
    <li>Fill missing values in the "Age" column with the mean age.</li>
    <li>Drop rows where "Salary" is missing. (Hint: Refer to Documentation)</li>
    <li>Remove duplicate rows if any.</li>
  </ol>
</p>
<details>
  <summary>Solution</summary>
  <div>
    <pre class="code-block">
import pandas as pd
import numpy as np

data = {'ID': [1, 2, 3, 4, 5],
        'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
        'Age': [25, np.nan, 30, 28, np.nan],
        'Salary': [50000, 55000, np.nan, 60000, np.nan]}
df = pd.DataFrame(data)

# 1. Fill missing values in the "Age" column with the mean age
mean_age = df['Age'].mean()
df['Age'] = df['Age'].fillna(mean_age)

# 2. Drop rows where "Salary" is missing
df_dropped_salary = df.dropna(subset=['Salary'])

# 3. Remove duplicate rows
df_dedup = df.drop_duplicates()

print(df)
print(df_dropped_salary)
print(df_dedup)
    </pre>
  </div>
</details>
<br>


<h4>6. Boolean Indexing with String Conditions</h4>
<p>
  Using the following code to create a DataFrame:
  <br><br>
  <pre class="code-block">
import pandas as pd

data = {'Product': ['Laptop', 'Tablet', 'Phone', 'Monitor', 'Projector'],
        'Category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics'],
        'Price': [1200, 300, 600, 200, 1500],
        'InStock': [True, False, True, True, False]}
df = pd.DataFrame(data)
  </pre>
  <ol>
    <li>Filter the DataFrame to include only the rows where the "Product" contains the letter 'o' (case-insensitive) and "InStock" is True.</li>
    <li>Filter the DataFrame to include only the rows where the "Product" starts with 'P' and ends with 'r', and the "Price" is greater than 500.</li>
    <li>Filter the DataFrame to include only the rows where the "Product" contains either 'e' or 't' (case-insensitive) and the "Price" is less than 1000.</li>
  </ol>
</p>
<details>
  <summary>Solution</summary>
  <div>
    <pre class="code-block">
import pandas as pd

data = {'Product': ['Laptop', 'Tablet', 'Phone', 'Monitor', 'Projector'],
        'Category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Electronics'],
        'Price': [1200, 300, 600, 200, 1500],
        'InStock': [True, False, True, True, False]}
df = pd.DataFrame(data)

# 1. Filter the DataFrame to include only the rows where the "Product" contains the letter 'o' (case-insensitive) and "InStock" is True
filtered_df_1 = df[df['Product'].str.contains('o', case=False) & df['InStock']]
print('Filter 1:\n', filtered_df_1)

# 2. Filter the DataFrame to include only the rows where the "Product" starts with 'P' and ends with 'r', and the "Price" is greater than 500
filtered_df_2 = df[df['Product'].str.startswith('P') & df['Product'].str.endswith('r') & (df['Price'] > 500)]
print('Filter 2:\n', filtered_df_2)

# 3. Filter the DataFrame to include only the rows where the "Product" contains either 'e' or 't' (case-insensitive) and the "Price" is less than 1000
filtered_df_3 = df[df['Product'].str.contains('e|t', case=False) & (df['Price'] < 1000)]
print('Filter 3:\n', filtered_df_3)
    </pre>
  </div>
</details>

<br>

<h4>7. Data Cleaning with Outliers</h4>
<p>
  Create a DataFrame with some outliers and perform the following tasks:
  <br><br>
  <pre class="code-block">
import pandas as pd

data = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
        'Value': [10, 200, 15, 300, 20, 25, 40, 600, 30, 35]}
df = pd.DataFrame(data)
  </pre>
  Perform the following tasks:
  <ol>
    <li>Identify and remove outliers in the "Value" column using the IQR method where outliers are defined as values that are more than 2 times the IQR above the third quartile or below the first quartile.</li>
    <li>Identify and remove outliers using a z-score method manually. An observation is considered an outlier if its z-score is greater than 2 or less than -2. Note: Use pandas to compute the mean and standard deviation.</li>
    <li>Compare the results from both methods and display the cleaned DataFrames and IQR values.</li>
  </ol>
</p>
<details>
  <summary>Solution</summary>
  <div>
    <pre class="code-block">
import pandas as pd

data = {'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
        'Value': [10, 200, 15, 300, 20, 25, 40, 600, 30, 35]}
df = pd.DataFrame(data)

# 1. Calculate the IQR and remove outliers
Q1 = df['Value'].quantile(0.25)
Q3 = df['Value'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 2 * IQR
upper_bound = Q3 + 2 * IQR
df_iqr_cleaned = df[(df['Value'] >= lower_bound) & (df['Value'] <= upper_bound)]

# 2. Calculate mean and standard deviation for Z-score method
mean = df['Value'].mean()
std = df['Value'].std()
df['Z-score'] = (df['Value'] - mean) / std

# Identify and remove outliers using Z-score method
df_zscore_cleaned = df[(df['Z-score'] <= 2) & (df['Z-score'] >= -2)]

# Drop the Z-score column for the final cleaned DataFrame
df_zscore_cleaned = df_zscore_cleaned.drop(columns='Z-score')

print(f'IQR: {IQR}')
print('Cleaned DataFrame (IQR method):\n', df_iqr_cleaned)
print('Cleaned DataFrame (Z-score method):\n', df_zscore_cleaned)
    </pre>
  </div>
</details>

<br>

<h4>8. Data Cleaning with Date and Time</h4>
<p>
  Create a DataFrame with some date and time data and perform the following tasks:
  <br><br>
  <pre class="code-block">
import pandas as pd

data = {'Event': ['Event1', 'Event2', 'Event3', 'Event4'],
        'Date': ['2024-01-01', '2024-02-01', '2024-01-15', '2024-02-15'],
        'Time': ['08:00', '09:00', '10:00', '11:00']}
df = pd.DataFrame(data)
df['Date'] = pd.to_datetime(df['Date'])
df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.time
  </pre>
  Perform the following tasks:
  <ol>
    <li>Filter the DataFrame to include only events that occur in January 2024.</li>
    <li>Compute and display the duration between the earliest and latest events in the DataFrame in terms of days.</li>
  </ol>
</p>
<details>
  <summary>Solution</summary>
  <div>
    <pre class="code-block">
import pandas as pd

data = {'Event': ['Event1', 'Event2', 'Event3', 'Event4'],
        'Date': ['2024-01-01', '2024-02-01', '2024-01-15', '2024-02-15'],
        'Time': ['08:00', '09:00', '10:00', '11:00']}
df = pd.DataFrame(data)
df['Date'] = pd.to_datetime(df['Date'])
df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.time

# 1. Filter for January 2024
df_january = df[df['Date'].dt.month == 1]

# 2. Compute the duration between the earliest and latest events
df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + ' ' + df['Time'].astype(str))
earliest_event = df['DateTime'].min()
latest_event = df['DateTime'].max()
duration_days = (latest_event - earliest_event).days

print(df_january)
print(f'Duration between earliest and latest events: {duration_days} days')
    </pre>
  </div>
</details>

<br>
        </section>
        

        <footer>
          <p>&copy; 2024 We Codez</p>
        </footer>
      </main>
    </div>
  </body>
</html>
